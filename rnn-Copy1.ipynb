{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpAuMVCwfWs8"
   },
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxJfRe4bfYVA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ir9zwETrfbrp"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZT1f24vHffuf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd #import dataset and make dataframe\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # to make arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQ47JAxrgmaL"
   },
   "source": [
    "### Importing the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xiv3pJOgqY3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>12/23/2016</td>\n",
       "      <td>790.90</td>\n",
       "      <td>792.74</td>\n",
       "      <td>787.28</td>\n",
       "      <td>789.91</td>\n",
       "      <td>623,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>12/27/2016</td>\n",
       "      <td>790.68</td>\n",
       "      <td>797.86</td>\n",
       "      <td>787.66</td>\n",
       "      <td>791.55</td>\n",
       "      <td>789,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>12/28/2016</td>\n",
       "      <td>793.70</td>\n",
       "      <td>794.23</td>\n",
       "      <td>783.20</td>\n",
       "      <td>785.05</td>\n",
       "      <td>1,153,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>12/29/2016</td>\n",
       "      <td>783.33</td>\n",
       "      <td>785.93</td>\n",
       "      <td>778.92</td>\n",
       "      <td>782.79</td>\n",
       "      <td>744,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>12/30/2016</td>\n",
       "      <td>782.75</td>\n",
       "      <td>782.78</td>\n",
       "      <td>770.41</td>\n",
       "      <td>771.82</td>\n",
       "      <td>1,770,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close      Volume\n",
       "0       1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1       1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2       1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3       1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4       1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n",
       "...          ...     ...     ...     ...     ...         ...\n",
       "1253  12/23/2016  790.90  792.74  787.28  789.91     623,400\n",
       "1254  12/27/2016  790.68  797.86  787.66  791.55     789,100\n",
       "1255  12/28/2016  793.70  794.23  783.20  785.05   1,153,800\n",
       "1256  12/29/2016  783.33  785.93  778.92  782.79     744,300\n",
       "1257  12/30/2016  782.75  782.78  770.41  771.82   1,770,000\n",
       "\n",
       "[1258 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we import training set as we will train only on train set \n",
    "# Here since we have train & test set so no need to split the dataset\n",
    "dataset_train = pd.read_csv(r'C:\\Users\\KUNAL\\Documents\\Deep_Learning\\Part 3 - Recurrent Neural Networks\\Google_Stock_Price_Train.csv')\n",
    "dataset_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.25],\n",
       "       [331.27],\n",
       "       [329.83],\n",
       "       ...,\n",
       "       [793.7 ],\n",
       "       [783.33],\n",
       "       [782.75]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we need to 2 things-1.)select then open Gsp column. 2.)Convert into numpy array by values as only numpy array are taken as inputs for NN\n",
    "training_set = dataset_train.iloc[:, 1:2].values\n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HT8_2UJegtG5"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OTrF2kR7gx9x"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))# feature values lies btw 0 & 1\n",
    "training_set_scaled = sc.fit_transform(training_set)# calling fit_transform method of minmaxscaler class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JyYgYocqhNUg"
   },
   "source": [
    "### Creating a data structure with 60 timesteps and 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iofU21B0i6ST"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-51-808102d54224>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-51-808102d54224>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    So for the day 1st jan 2017 we will look at the tree previous months 1st jan of\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Can try different time steps- 60 Time steps-means 3 months. \n",
    "So for the day 1st jan 2017 we will look at the tree previous months 1st jan of \n",
    "# Create a datastructure specifying what rnn need to remember for predicting the next stock price -called no. of Timesteps\n",
    "#60 timesteps- Rnn is going to look at 60 stock prices(days) before time T of past stock prices & rnn will learn,\n",
    "#understand correlations,trends & based on it will predict the next output i.e the stock price at time T+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []# inputs will contain 60 previous stock prices before the financial day\n",
    "y_train = []# output will contain the stock price next financial day\n",
    "for i in range(60,1258):#Lower bound as 60 as from 60th financial day of 2012 i-60 and then to i  i.e before Time T & Upper bound is 1258 i.e total no. of rows in our dataset\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])# 0 to 59 i.e 60 as upperbound is not counted(range in []),0 specifies the column we have to take from X_train_scaled\n",
    "    y_train.append(training_set_scaled[i, 0])# here we take 60 as we want to predict stock price at T+1 i.e 59+1=60\n",
    "X_train,y_train=np.array(X_train),np.array(y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368, 0.09701243, 0.09433366, ..., 0.07846566, 0.08034452,\n",
       "        0.08497656],\n",
       "       [0.09701243, 0.09433366, 0.09156187, ..., 0.08034452, 0.08497656,\n",
       "        0.08627874],\n",
       "       [0.09433366, 0.09156187, 0.07984225, ..., 0.08497656, 0.08627874,\n",
       "        0.08471612],\n",
       "       ...,\n",
       "       [0.92106928, 0.92438053, 0.93048218, ..., 0.95475854, 0.95204256,\n",
       "        0.95163331],\n",
       "       [0.92438053, 0.93048218, 0.9299055 , ..., 0.95204256, 0.95163331,\n",
       "        0.95725128],\n",
       "       [0.93048218, 0.9299055 , 0.93113327, ..., 0.95163331, 0.95725128,\n",
       "        0.93796041]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198, 60)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08627874, 0.08471612, 0.07454052, ..., 0.95725128, 0.93796041,\n",
       "       0.93688146])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8yaN7Zvi95l"
   },
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOXqJHmNjBkz"
   },
   "outputs": [],
   "source": [
    "# Adding more no. of Predictors/indicators i.e columns to predict trends in Gsp\n",
    "X_train=np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))# 2 arguments the data,specify the new shape to have\n",
    "#The 2nd argument - no. of batch size,timesteps-1 represents the no. of Timesteps,indicators\n",
    "# So now are X_train is in 3d view Rows-1258,columns=60 timesteps,indicators=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZRRSOJeVjEWV"
   },
   "source": [
    "## Part 2 - Building and Training the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k4XV88JMjHXG"
   },
   "source": [
    "### Importing the Keras libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9JRnqsxEjKsD",
    "outputId": "b3e23e78-18aa-4396-c923-c877b8de60e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "#Sequential class -builds a NN\n",
    "#Dense class-to add input & output layer\n",
    "# Lstm- to add lstm layers\n",
    "# Dropout-to dropout Regularisation\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FEIE-1s9jNzC"
   },
   "source": [
    "### Initialising the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1338dJ0UjRKH"
   },
   "outputs": [],
   "source": [
    "regressor=Sequential()# Regressor is an object of sequential class that represents sequence of layers\n",
    "#Why Regressor as we are predicting the continous values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "62eg1OPGjT8z"
   },
   "source": [
    "### Adding the first LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2hIinyXUjbVU"
   },
   "outputs": [],
   "source": [
    "# Add 2 layers-1.)Lstm,2.)Dropout layers\n",
    "# LSTM-WE need to add 3 arguments-1.)no. of units/neurons-no. of lstm units/cells to have in the stacked lstm layer-in this we choose\n",
    "#50 as we need to have high dimensionality/neurons.2.)return_Sequences-true as we are gonna add more layers to make a stacked lstm nn\n",
    "#3.)input_shape only take last 2 arguments i.e timesteps & indicators and take no. of rows as default\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))# we call add object of Lstm class\n",
    "#adding some dropout regularisation to avoid overfitting- 20% as classic dropout of neurons-tells the no. of neurons we need to drop\n",
    "# we will be droping 0.2 neurons during FP & Bp in each iteration and 20% of 50 neurons is 10 will be dropped in each iteration of training\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3XBIYLyOjlMx"
   },
   "source": [
    "### Adding a second LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UG7nrVaSjuZ2"
   },
   "outputs": [],
   "source": [
    "# No need to write the input_shape-as due to units i.e no. of neurons we get to know the input_shape\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ey3fHVnGj1cu"
   },
   "source": [
    "### Adding a third LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PuNi6PgFj7jO"
   },
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYTrtfTmj933"
   },
   "source": [
    "### Adding a fourth LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jp4Ty8fRkBYV"
   },
   "outputs": [],
   "source": [
    "#return_Sequence as false as we need not add more lstm layers\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ABI6rOIkHhk"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aM6R1z4WkME8"
   },
   "outputs": [],
   "source": [
    "# For making a fully connected layer we use Dense class-units as 1 as we are predicted only one output i.e no. of neurons i.e stock price at time T+1\n",
    "regressor.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zLx4K7uUkPSh"
   },
   "source": [
    "### Compiling the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XTrhVN-tkbko"
   },
   "outputs": [],
   "source": [
    "# Optimiser performs SGD by adam/RMSprop to update the weights in each iteration's and reduce the loss i.e cost function\n",
    "regressor.compile(optimizer='adam',loss='mean_squared_error')\n",
    "# not take metrics as at last will print the error & the r2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mPhwKGkkebi"
   },
   "source": [
    "### Fitting the RNN to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "I06Nkrz5kkb-",
    "outputId": "dc9d947a-4d5c-4dbc-ed45-31bf44b98dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 0.0411\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 0.0060\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.0056\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 0.0048\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0050\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 6s 145ms/step - loss: 0.0050\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 6s 157ms/step - loss: 0.0047\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 5s 142ms/step - loss: 0.0047\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 6s 162ms/step - loss: 0.0047\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 5s 140ms/step - loss: 0.0052\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0049\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0042\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0040\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 5s 142ms/step - loss: 0.0038\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0039\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 0.0035\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0042\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0036\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 0.0036\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0038\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.0039\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 0.0033\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 0.0032\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0032\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 6s 150ms/step - loss: 0.0033\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0035\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 6s 156ms/step - loss: 0.0039\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 5s 144ms/step - loss: 0.0033\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 6s 146ms/step - loss: 0.0027\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 6s 149ms/step - loss: 0.0030\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0029\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 6s 145ms/step - loss: 0.0029\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 6s 153ms/step - loss: 0.0028\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 5s 137ms/step - loss: 0.0026\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0029\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0026\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 0.0028\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0027\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 5s 138ms/step - loss: 0.0035\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0025\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 5s 137ms/step - loss: 0.0026\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.0024\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 5s 144ms/step - loss: 0.0025\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0026\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 5s 141ms/step - loss: 0.0023\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 0.0028\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0024\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 6s 170ms/step - loss: 0.0025\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 8s 217ms/step - loss: 0.0023\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 8s 205ms/step - loss: 0.0026\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 9s 225ms/step - loss: 0.0022\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 8s 208ms/step - loss: 0.0025\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 8s 215ms/step - loss: 0.0024\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 7s 188ms/step - loss: 0.0021\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 8s 198ms/step - loss: 0.0022\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 7s 197ms/step - loss: 0.0023\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 5s 141ms/step - loss: 0.0020\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 5s 142ms/step - loss: 0.0023\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 5s 139ms/step - loss: 0.0023\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.0023\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0021\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0020\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 0.0020\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0019\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.0018\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0021\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0018\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0020\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.0020\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 5s 142ms/step - loss: 0.0018\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 5s 140ms/step - loss: 0.0018\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0020\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 0.0017\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0017\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.0020\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.0021\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0017\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 5s 139ms/step - loss: 0.0017\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 6s 147ms/step - loss: 0.0017\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.0018\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 5s 140ms/step - loss: 0.0017\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 0.0016\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 5s 137ms/step - loss: 0.0017\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 0.0017\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0017\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 5s 138ms/step - loss: 0.0015\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 5s 141ms/step - loss: 0.0014\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0016\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0016\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0015\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 0.0017\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.0015\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 5s 137ms/step - loss: 0.0015\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0015\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0015\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 5s 137ms/step - loss: 0.0015\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0015\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 5s 138ms/step - loss: 0.0014\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0015\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 0.0014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24f628a13c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train,epochs=100,batch_size=32)#epochs-how many times we need to train(FP & BP) our dataset on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hRau_lIkrE8"
   },
   "source": [
    "## Part 3 - Making the predictions and visualising the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SgJO6qEDksxD"
   },
   "source": [
    "### Getting the real stock price of 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FmBT2zqukxTz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[778.81],\n",
       "       [788.36],\n",
       "       [786.08],\n",
       "       [795.26],\n",
       "       [806.4 ],\n",
       "       [807.86],\n",
       "       [805.  ],\n",
       "       [807.14],\n",
       "       [807.48],\n",
       "       [807.08],\n",
       "       [805.81],\n",
       "       [805.12],\n",
       "       [806.91],\n",
       "       [807.25],\n",
       "       [822.3 ],\n",
       "       [829.62],\n",
       "       [837.81],\n",
       "       [834.71],\n",
       "       [814.66],\n",
       "       [796.86]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test = pd.read_csv(r'C:\\Users\\KUNAL\\Documents\\Deep_Learning\\Part 3 - Recurrent Neural Networks\\Google_Stock_Price_Test.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "real_stock_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GrvrLblxkz42"
   },
   "source": [
    "### Getting the predicted stock price of 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emikTvUpk3Ck"
   },
   "outputs": [],
   "source": [
    "# predict the gsp of jan 2017 -so we have trained our to predict the stock price at T+1 by previous 60 financial days \n",
    "#in order to predict we need both training & test set\n",
    "#1.)Concatenation of train & test set-we use concat not concatenation as we need both real data of train & test \n",
    "# Get the dataset from 2012 to 2016 and jan 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)# concatenate the columns i.e vertical axis=0,horizontal axis=1\n",
    "# get the inputs by dataset_total we do 1 st financial day i.e 3rd jan - to last financial day\n",
    "inputs=dataset_total[len(dataset_total)-len(dataset_test)-60:].values\n",
    "inputs=inputs.reshape(-1,1)# to get right numpy shape \n",
    "inputs=sc.transform(inputs)#transforming i.e scaling the valuesn on original dataset by minmaxscaler\n",
    "# now to build the 3-d structure of test set first append the values in X_test & y_test\n",
    "X_test = []\n",
    "for i in range(60,80):# we take previous 60 days stock price and at T+1 other 20 financial days\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test=np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predicted_stock_price=regressor.predict(X_test)#y_pred\n",
    "predicted_stock_price=sc.inverse_transform(predicted_stock_price)# now so as to get predicted stock price not in 0 & 1 range\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[805.74786],\n",
       "       [803.01953],\n",
       "       [802.3043 ],\n",
       "       [803.06226],\n",
       "       [805.992  ],\n",
       "       [811.6509 ],\n",
       "       [817.8015 ],\n",
       "       [821.6429 ],\n",
       "       [823.1378 ],\n",
       "       [823.1105 ],\n",
       "       [822.4235 ],\n",
       "       [821.5591 ],\n",
       "       [820.8708 ],\n",
       "       [820.96094],\n",
       "       [821.74695],\n",
       "       [825.67084],\n",
       "       [832.3574 ],\n",
       "       [840.42773],\n",
       "       [846.3149 ],\n",
       "       [845.0122 ]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_stock_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'concat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-ccfe829a8c33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_stock_price\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreal_stock_price\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Open'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AnacondaN\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 raise AttributeError(\"module {!r} has no attribute \"\n\u001b[1;32m--> 220\u001b[1;33m                                      \"{!r}\".format(__name__, attr))\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'concat'"
     ]
    }
   ],
   "source": [
    "print(pd.concat((predicted_stock_price,real_stock_price['Open']),axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFTNs3YHk6FQ"
   },
   "source": [
    "### Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "8OUI8U49k9tH",
    "outputId": "db0ed15e-071b-4bae-955e-0eda3df95238"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.262630251738003"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "rmse = math.sqrt(mean_squared_error(real_stock_price, predicted_stock_price))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.37111842097724246"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=r2_score(real_stock_price, predicted_stock_price)\n",
    "score\n",
    "relation btw predicted and actual values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "recurrent_neural_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
